{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01fba671-6040-4986-b57a-339c1c16c036",
   "metadata": {},
   "source": [
    "# Project Lama Into the Wild: Transfer Learning & Domain Similarity metrics\n",
    "<b>Group Number: 13</b><br>\n",
    "<b>Name Group Member 1: Léo Brucker</b><br>\n",
    "<b>u-Kürzel Group Member 1: uhugu</b><br>\n",
    "<b>Name Group Member 2: Cyril Rudolph</b><br>\n",
    "<b>u-Kürzel Group Member 2: udjvh</b>\n",
    "## Project Description:\n",
    "### Primary Milestone:\n",
    "Goal: Transfer Learning (Domain Adaptation) in Precision Agriculture.\n",
    "<br>Task: train a model for classification and evaluate it in different domains.\n",
    "\n",
    "Understand the problems of Federated learning and class imbalance by first trying to apply a model that can transfer the “global model” onto local small datasets (defined by different clients in the emnist dataset).\n",
    "\n",
    "### Secondary Milestone:\n",
    "Use Federated Transfer Learning on a more complex dataset with two types of class categories (plant type and plant health). One of these types of classes will be used to simulate the clients (for the federated learning part): For example we could only have access to pictures of healthy plants, but we will need to also recognize sick plants. We will also analyze the effects of class imbalance (compare arXiv:2109.04094v2) and try to mitigate them. \n",
    "\n",
    "## Roadmap\n",
    "- [ ] Implement a Federated Transfer Learning Model on the emnist Dataset. Create/Adapt a first model and test it.\n",
    "- [ ] Implement Class Imbalance (by manually creating it in the dataset or using existing imbalance from the dataset) and train a model to reduce this imbalance as much as possible.\n",
    "- [ ] Data preparation and visualization of the Plant Village dataset. Transfer the emnist model to the more complex dataset and build upon it.\n",
    "- [ ] Evaluation of the results, what are valuable methods to reduce class imbalance?\n",
    "\n",
    "#### Nice links:\n",
    "- https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc70541-54b3-4e31-aa3a-f8fcca80b363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 14:53:17.775123: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-29 14:53:17.961879: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-29 14:53:17.961908: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-29 14:53:17.961937: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-29 14:53:17.970914: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-29 14:53:17.971840: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-29 14:53:19.229613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83690a9d",
   "metadata": {},
   "source": [
    "#### Implementation of Multiclass Imbalance Degree (MID)\n",
    "\n",
    "The paper uses the general approach of LRID and but combines it, which leaves us with following equation:\n",
    "$ Test = 123 $\n",
    "\n",
    "$$ MID = \\left(\\frac{LRID}{LRID_ext} \\right) = \\left( \\sum_{c=1}^C \\frac{n_c}{N} *log_C(\\frac{C_n}{N})\\right)\n",
    "$$\n",
    "<br>\n",
    "\n",
    "with $N = Datasamples$, $C = possible classes$, the number of sampels with label c is $n_c$\n",
    "The larger the number (between 0 & 1) the more the dataset is unbalanced.\n",
    "\n",
    "#### Implementation of Weighted Cosine Similarity (WCS)\n",
    "The mean cosine similarity (MCS) on which the WCS is based, can not consider the clients sample size, which leads to potentially biased estimation of the global and local imbalance relation. \n",
    "$$\n",
    "WCS=  \\sum_{i=1}^P \\frac{||l_i||_1 L * l_i}{||L||_1 ||L||_2 ||l_i||_2} = \\frac{1}{||L||_1 ||L||_2} \\sum_{i=1}^P \\frac{||l_i||_1}{||l_i||_2} L*l_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce20a91-7596-4b0d-b864-2a9fe36fc398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 14:53:22.863074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-29 14:53:22.865891: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of client datasets: 10\n",
      "First dataset: <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>\n"
     ]
    }
   ],
   "source": [
    "# Load the femnist dataset\n",
    "\n",
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(only_digits=True, cache_dir=None)\n",
    "\n",
    "NUM_CLIENTS = 10 # number of clients (writers) we will work with\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "SHUFFLE_BUFFER = 100\n",
    "PREFETCH_BUFFER = 10\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "  def batch_format_fn(element):\n",
    "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict` (x,y).\"\"\"\n",
    "    return collections.OrderedDict(\n",
    "        x=tf.reshape(element['pixels'], [-1, 784]),\n",
    "        y=tf.reshape(element['label'], [-1, 1]))\n",
    "\n",
    "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(\n",
    "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
    "\n",
    "\n",
    "# Create list of multiple given client datasets\n",
    "def make_federated_data(client_data, client_ids): \n",
    "  return [\n",
    "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
    "      for x in client_ids\n",
    "  ]\n",
    "\n",
    "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
    "\n",
    "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
    "\n",
    "print(f'Number of client datasets: {len(federated_train_data)}')\n",
    "print(f'First dataset: {federated_train_data[0]}')\n",
    "\n",
    "example_dataset = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[0])\n",
    "preprocessed_example_dataset = preprocess(example_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f92022",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize\n",
    "\n",
    "visualize = False\n",
    "\n",
    "if(visualize):\n",
    "  # Number of examples per layer for a sample of clients -> We can see some class imbalance is present\n",
    "  f = plt.figure(figsize=(12, 7))\n",
    "  f.suptitle('Label Counts for a Sample of Clients')\n",
    "  for i in range(6):\n",
    "    client_dataset = emnist_train.create_tf_dataset_for_client(\n",
    "        emnist_train.client_ids[i])\n",
    "    plot_data = collections.defaultdict(list)\n",
    "    for example in client_dataset:\n",
    "      label = example['label'].numpy()\n",
    "      plot_data[label].append(label)\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.title('Client {}'.format(i))\n",
    "    for j in range(10):\n",
    "      plt.hist(\n",
    "          plot_data[j],\n",
    "          density=False,\n",
    "          bins=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "  _ = plt.show()\n",
    "  # Each client has different mean images, meaning each client will be nudging\n",
    "  # the model in their own directions locally.\n",
    "\n",
    "  for i in range(3):\n",
    "    client_dataset = emnist_train.create_tf_dataset_for_client(\n",
    "        emnist_train.client_ids[i])\n",
    "    plot_data = collections.defaultdict(list)\n",
    "    for example in client_dataset:\n",
    "      plot_data[example['label'].numpy()].append(example['pixels'].numpy())\n",
    "    f = plt.figure(i, figsize=(12, 5))\n",
    "    f.suptitle(\"Client #{}'s Mean Image Per Label\".format(i))\n",
    "    for j in range(10):\n",
    "        mean_img = np.mean(plot_data[j], 0)\n",
    "        plt.subplot(2, 5, j+1)\n",
    "        plt.imshow(mean_img.reshape((28, 28)))\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc3537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "\n",
    "# Create a tensorflow (keras) model\n",
    "def create_keras_model():\n",
    "  initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
    "  return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Input(shape=(784,)),                          ## Input 784 pixels\n",
    "      tf.keras.layers.Dense(10, kernel_initializer=initializer),    ## 10 fully-connected neurons\n",
    "      tf.keras.layers.Softmax(),                                    ## One-hot encoding\n",
    "  ])\n",
    "\n",
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "  keras_model = create_keras_model()\n",
    "  return tff.learning.models.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=preprocessed_example_dataset.element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0597d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 15:23:51.496993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-29 15:23:51.497161: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-01-29 15:23:51.497278: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-01-29 15:23:51.497746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-29 15:23:51.497857: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-01-29 15:23:51.607087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-29 15:23:51.607262: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-01-29 15:23:51.607359: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-01-29 15:23:51.607728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-29 15:23:51.607835: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m training_process \u001b[38;5;241m=\u001b[39m tff\u001b[38;5;241m.\u001b[39mlearning\u001b[38;5;241m.\u001b[39malgorithms\u001b[38;5;241m.\u001b[39mbuild_weighted_fed_avg(\n\u001b[1;32m      4\u001b[0m     model_fn,   \n\u001b[1;32m      5\u001b[0m     client_optimizer_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m),\n\u001b[1;32m      6\u001b[0m     server_optimizer_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Uncomment to see the representation of the training process\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#print(training_process.initialize.type_signature.formatted_representation())\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Initialize: Construct the server state\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m train_state \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Next: A single round of federated averaging (push server state to clients -> local updates -> collect and average to new server state\u001b[39;00m\n\u001b[1;32m     15\u001b[0m result \u001b[38;5;241m=\u001b[39m training_process\u001b[38;5;241m.\u001b[39mnext(train_state, federated_train_data)\n",
      "File \u001b[0;32m~/Documents/git-repos/lama_ItW/itw_env/lib/python3.10/site-packages/tensorflow_federated/python/core/impl/computation/computation_impl.py:151\u001b[0m, in \u001b[0;36mConcreteComputation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    146\u001b[0m   arg \u001b[38;5;241m=\u001b[39m function_utils\u001b[38;5;241m.\u001b[39mpack_args(\n\u001b[1;32m    147\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type_signature\u001b[38;5;241m.\u001b[39mparameter,  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[1;32m    148\u001b[0m       args,\n\u001b[1;32m    149\u001b[0m       kwargs,\n\u001b[1;32m    150\u001b[0m   )\n\u001b[0;32m--> 151\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_result(result)\n",
      "File \u001b[0;32m~/Documents/git-repos/lama_ItW/itw_env/lib/python3.10/site-packages/tensorflow_federated/python/core/impl/execution_contexts/sync_execution_context.py:65\u001b[0m, in \u001b[0;36mSyncExecutionContext.invoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, comp, arg):\n\u001b[0;32m---> 65\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_coro_and_return_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git-repos/lama_ItW/itw_env/lib/python3.10/site-packages/tensorflow_federated/python/common_libs/async_utils.py:149\u001b[0m, in \u001b[0;36mAsyncThreadRunner.run_coro_and_return_result\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs coroutine in the managed event loop, returning the result.\"\"\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(coro, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_loop)\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Train!\n",
    "\n",
    "training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,   \n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
    "\n",
    "# Uncomment to see the representation of the training process\n",
    "#print(training_process.initialize.type_signature.formatted_representation())\n",
    "\n",
    "# Initialize: Construct the server state\n",
    "train_state = training_process.initialize()\n",
    "\n",
    "# Next: A single round of federated averaging (push server state to clients -> local updates -> collect and average to new server state\n",
    "result = training_process.next(train_state, federated_train_data)\n",
    "train_state = result.state\n",
    "train_metrics = result.metrics\n",
    "print('round  1, metrics={}'.format(train_metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630449f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itw_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
